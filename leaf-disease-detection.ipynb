{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3814063,"sourceType":"datasetVersion","datasetId":2272471}],"dockerImageVersionId":30748,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tensorflow --upgrade ","metadata":{"execution":{"iopub.status.busy":"2024-08-03T13:28:16.291249Z","iopub.execute_input":"2024-08-03T13:28:16.291964Z","iopub.status.idle":"2024-08-03T13:29:23.108451Z","shell.execute_reply.started":"2024-08-03T13:28:16.291928Z","shell.execute_reply":"2024-08-03T13:29:23.107528Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.15.0)\nCollecting tensorflow\n  Downloading tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nCollecting flatbuffers>=24.3.25 (from tensorflow)\n  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\nCollecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow)\n  Downloading ml_dtypes-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.32.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.9.0)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.60.0)\nCollecting tensorboard<2.18,>=2.17 (from tensorflow)\n  Downloading tensorboard-2.17.0-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: keras>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.4.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.35.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (13.7.0)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (0.0.8)\nRequirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (0.12.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.5.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.3)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow) (2.17.2)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\nDownloading tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (601.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m601.3/601.3 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\nDownloading ml_dtypes-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading tensorboard-2.17.0-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: flatbuffers, ml-dtypes, tensorboard, tensorflow\n  Attempting uninstall: flatbuffers\n    Found existing installation: flatbuffers 23.5.26\n    Uninstalling flatbuffers-23.5.26:\n      Successfully uninstalled flatbuffers-23.5.26\n  Attempting uninstall: ml-dtypes\n    Found existing installation: ml-dtypes 0.2.0\n    Uninstalling ml-dtypes-0.2.0:\n      Successfully uninstalled ml-dtypes-0.2.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.15.1\n    Uninstalling tensorboard-2.15.1:\n      Successfully uninstalled tensorboard-2.15.1\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.15.0\n    Uninstalling tensorflow-2.15.0:\n      Successfully uninstalled tensorflow-2.15.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\ntensorflow-decision-forests 1.8.1 requires tensorflow~=2.15.0, but you have tensorflow 2.17.0 which is incompatible.\ntensorflow-text 2.15.0 requires tensorflow<2.16,>=2.15.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.17.0 which is incompatible.\ntf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.17.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed flatbuffers-24.3.25 ml-dtypes-0.4.0 tensorboard-2.17.0 tensorflow-2.17.0\n","output_type":"stream"}]},{"cell_type":"code","source":"#Required Libraries\nimport numpy as np\nimport pandas as pd\nimport os\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom tensorflow import *\nfrom tensorflow import keras\nfrom keras.models import Sequential, Model\nfrom tensorflow.keras.applications import *\nfrom keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Dropout,BatchNormalization,GlobalAveragePooling2D\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-08-03T15:15:46.424544Z","iopub.execute_input":"2024-08-03T15:15:46.425220Z","iopub.status.idle":"2024-08-03T15:15:46.432693Z","shell.execute_reply.started":"2024-08-03T15:15:46.425188Z","shell.execute_reply":"2024-08-03T15:15:46.431726Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"#Copy and paste the training and testing folder in training and testing variable\ntraining_folder=r\"/kaggle/input/leaf-disease-detection-dataset/dataset/train\"\ntesting_folder=r\"/kaggle/input/leaf-disease-detection-dataset/dataset/test\"","metadata":{"execution":{"iopub.status.busy":"2024-08-03T13:30:55.693948Z","iopub.execute_input":"2024-08-03T13:30:55.694307Z","iopub.status.idle":"2024-08-03T13:30:55.699287Z","shell.execute_reply.started":"2024-08-03T13:30:55.694277Z","shell.execute_reply":"2024-08-03T13:30:55.698466Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Find the Number of classess\nnumber_of_classes=len(os.listdir(training_folder))\nprint(f\"Number of classes: {number_of_classes}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-03T13:30:57.150753Z","iopub.execute_input":"2024-08-03T13:30:57.151138Z","iopub.status.idle":"2024-08-03T13:30:57.455990Z","shell.execute_reply.started":"2024-08-03T13:30:57.151108Z","shell.execute_reply":"2024-08-03T13:30:57.454947Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Number of classes: 38\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1722691857.182895      34 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\nI0000 00:00:1722691857.327121      34 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\nI0000 00:00:1722691857.327379      34 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\nI0000 00:00:1722691857.330096      34 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\nI0000 00:00:1722691857.330320      34 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\nI0000 00:00:1722691857.330506      34 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\nI0000 00:00:1722691857.432994      34 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\nI0000 00:00:1722691857.433213      34 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\nI0000 00:00:1722691857.433387      34 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","output_type":"stream"}]},{"cell_type":"code","source":"#Find the Number of images in Training folder\ntotal_number_of_images_in_training=0\nfolder_path=os.listdir(training_folder)\nfor i,folder in enumerate(folder_path):\n    number_of_images=len(os.listdir(training_folder+'/'+folder))\n    total_number_of_images_in_training+=number_of_images\n    print(f\"{i} , In {folder} folder contains {number_of_images} images.\")\n\nprint(f\"Total Number of Images in Training Folder: {total_number_of_images_in_training}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-03T11:54:09.780208Z","iopub.execute_input":"2024-08-03T11:54:09.780564Z","iopub.status.idle":"2024-08-03T11:54:09.911343Z","shell.execute_reply.started":"2024-08-03T11:54:09.780534Z","shell.execute_reply":"2024-08-03T11:54:09.910417Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"0 , In Tomato___Late_blight folder contains 1851 images.\n1 , In Tomato___healthy folder contains 1926 images.\n2 , In Grape___healthy folder contains 1692 images.\n3 , In Orange___Haunglongbing_(Citrus_greening) folder contains 2010 images.\n4 , In Soybean___healthy folder contains 2022 images.\n5 , In Squash___Powdery_mildew folder contains 1736 images.\n6 , In Potato___healthy folder contains 1824 images.\n7 , In Corn_(maize)___Northern_Leaf_Blight folder contains 1908 images.\n8 , In Tomato___Early_blight folder contains 1920 images.\n9 , In Tomato___Septoria_leaf_spot folder contains 1745 images.\n10 , In Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot folder contains 1642 images.\n11 , In Strawberry___Leaf_scorch folder contains 1774 images.\n12 , In Peach___healthy folder contains 1728 images.\n13 , In Apple___Apple_scab folder contains 2016 images.\n14 , In Tomato___Tomato_Yellow_Leaf_Curl_Virus folder contains 1961 images.\n15 , In Tomato___Bacterial_spot folder contains 1702 images.\n16 , In Apple___Black_rot folder contains 1987 images.\n17 , In Blueberry___healthy folder contains 1816 images.\n18 , In Cherry_(including_sour)___Powdery_mildew folder contains 1683 images.\n19 , In Peach___Bacterial_spot folder contains 1838 images.\n20 , In Apple___Cedar_apple_rust folder contains 1760 images.\n21 , In Tomato___Target_Spot folder contains 1827 images.\n22 , In Pepper,_bell___healthy folder contains 1988 images.\n23 , In Grape___Leaf_blight_(Isariopsis_Leaf_Spot) folder contains 1722 images.\n24 , In Potato___Late_blight folder contains 1939 images.\n25 , In Tomato___Tomato_mosaic_virus folder contains 1790 images.\n26 , In Strawberry___healthy folder contains 1824 images.\n27 , In Apple___healthy folder contains 2008 images.\n28 , In Grape___Black_rot folder contains 1888 images.\n29 , In Potato___Early_blight folder contains 1939 images.\n30 , In Cherry_(including_sour)___healthy folder contains 1826 images.\n31 , In Corn_(maize)___Common_rust_ folder contains 1907 images.\n32 , In Grape___Esca_(Black_Measles) folder contains 1920 images.\n33 , In Raspberry___healthy folder contains 1781 images.\n34 , In Tomato___Leaf_Mold folder contains 1882 images.\n35 , In Tomato___Spider_mites Two-spotted_spider_mite folder contains 1741 images.\n36 , In Pepper,_bell___Bacterial_spot folder contains 1913 images.\n37 , In Corn_(maize)___healthy folder contains 1859 images.\nTotal Number of Images in Training Folder: 70295\n","output_type":"stream"}]},{"cell_type":"code","source":"#Find the Number of images in Testing folder\ntotal_number_of_images_in_testing=0\nfolder_path=os.listdir(testing_folder)\nfor i,folder in enumerate(folder_path):\n    number_of_images=len(os.listdir(testing_folder+'/'+folder))\n    total_number_of_images_in_testing+=number_of_images\n    print(f\"{i}, In {folder} folder contains {number_of_images} images.\")\n\nprint(f\"Total Number of Images in Testing Folder: {total_number_of_images_in_testing}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-03T11:54:14.868790Z","iopub.execute_input":"2024-08-03T11:54:14.869147Z","iopub.status.idle":"2024-08-03T11:54:14.979599Z","shell.execute_reply.started":"2024-08-03T11:54:14.869118Z","shell.execute_reply":"2024-08-03T11:54:14.978775Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"0, In Tomato___Late_blight folder contains 463 images.\n1, In Tomato___healthy folder contains 481 images.\n2, In Grape___healthy folder contains 423 images.\n3, In Orange___Haunglongbing_(Citrus_greening) folder contains 503 images.\n4, In Soybean___healthy folder contains 505 images.\n5, In Squash___Powdery_mildew folder contains 434 images.\n6, In Potato___healthy folder contains 456 images.\n7, In Corn_(maize)___Northern_Leaf_Blight folder contains 477 images.\n8, In Tomato___Early_blight folder contains 480 images.\n9, In Tomato___Septoria_leaf_spot folder contains 436 images.\n10, In Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot folder contains 410 images.\n11, In Strawberry___Leaf_scorch folder contains 444 images.\n12, In Peach___healthy folder contains 432 images.\n13, In Apple___Apple_scab folder contains 504 images.\n14, In Tomato___Tomato_Yellow_Leaf_Curl_Virus folder contains 490 images.\n15, In Tomato___Bacterial_spot folder contains 425 images.\n16, In Apple___Black_rot folder contains 497 images.\n17, In Blueberry___healthy folder contains 454 images.\n18, In Cherry_(including_sour)___Powdery_mildew folder contains 421 images.\n19, In Peach___Bacterial_spot folder contains 459 images.\n20, In Apple___Cedar_apple_rust folder contains 440 images.\n21, In Tomato___Target_Spot folder contains 457 images.\n22, In Pepper,_bell___healthy folder contains 497 images.\n23, In Grape___Leaf_blight_(Isariopsis_Leaf_Spot) folder contains 430 images.\n24, In Potato___Late_blight folder contains 485 images.\n25, In Tomato___Tomato_mosaic_virus folder contains 448 images.\n26, In Strawberry___healthy folder contains 456 images.\n27, In Apple___healthy folder contains 502 images.\n28, In Grape___Black_rot folder contains 472 images.\n29, In Potato___Early_blight folder contains 485 images.\n30, In Cherry_(including_sour)___healthy folder contains 456 images.\n31, In Corn_(maize)___Common_rust_ folder contains 477 images.\n32, In Grape___Esca_(Black_Measles) folder contains 480 images.\n33, In Raspberry___healthy folder contains 445 images.\n34, In Tomato___Leaf_Mold folder contains 470 images.\n35, In Tomato___Spider_mites Two-spotted_spider_mite folder contains 435 images.\n36, In Pepper,_bell___Bacterial_spot folder contains 478 images.\n37, In Corn_(maize)___healthy folder contains 465 images.\nTotal Number of Images in Testing Folder: 17572\n","output_type":"stream"}]},{"cell_type":"code","source":"#To Get the filename with pathname and folder name for label for Training Folder\nfile_path=[] # File name\nlabel=[]  # folder name\nfor subfolder in os.listdir(training_folder):\n    sub_folder_path=os.path.join(training_folder,subfolder)\n    if os.path.isdir(sub_folder_path):\n        for file_name in os.listdir(sub_folder_path):\n            path=os.path.join(sub_folder_path,file_name)\n            if os.path.isfile(path):\n                file_path.append(path)\n                label.append(subfolder)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T11:54:21.284828Z","iopub.execute_input":"2024-08-03T11:54:21.285619Z","iopub.status.idle":"2024-08-03T11:55:28.000956Z","shell.execute_reply.started":"2024-08-03T11:54:21.285590Z","shell.execute_reply":"2024-08-03T11:55:28.000140Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# To create a Dataframe for the training data\ndata={\n    'file_path':file_path,\n    'label':label\n}\ntrain_df=pd.DataFrame(data)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-03T11:56:07.635283Z","iopub.execute_input":"2024-08-03T11:56:07.635662Z","iopub.status.idle":"2024-08-03T11:56:07.652729Z","shell.execute_reply.started":"2024-08-03T11:56:07.635619Z","shell.execute_reply":"2024-08-03T11:56:07.651777Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#Check the Training data\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T11:56:13.993265Z","iopub.execute_input":"2024-08-03T11:56:13.993630Z","iopub.status.idle":"2024-08-03T11:56:14.008600Z","shell.execute_reply.started":"2024-08-03T11:56:13.993600Z","shell.execute_reply":"2024-08-03T11:56:14.007506Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                           file_path                 label\n0  /kaggle/input/leaf-disease-detection-dataset/d...  Tomato___Late_blight\n1  /kaggle/input/leaf-disease-detection-dataset/d...  Tomato___Late_blight\n2  /kaggle/input/leaf-disease-detection-dataset/d...  Tomato___Late_blight\n3  /kaggle/input/leaf-disease-detection-dataset/d...  Tomato___Late_blight\n4  /kaggle/input/leaf-disease-detection-dataset/d...  Tomato___Late_blight","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_path</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/leaf-disease-detection-dataset/d...</td>\n      <td>Tomato___Late_blight</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/leaf-disease-detection-dataset/d...</td>\n      <td>Tomato___Late_blight</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/leaf-disease-detection-dataset/d...</td>\n      <td>Tomato___Late_blight</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/leaf-disease-detection-dataset/d...</td>\n      <td>Tomato___Late_blight</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/leaf-disease-detection-dataset/d...</td>\n      <td>Tomato___Late_blight</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Shape of the Training Data\ntrain_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-03T11:56:17.337121Z","iopub.execute_input":"2024-08-03T11:56:17.337835Z","iopub.status.idle":"2024-08-03T11:56:17.343681Z","shell.execute_reply.started":"2024-08-03T11:56:17.337801Z","shell.execute_reply":"2024-08-03T11:56:17.342684Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(70295, 2)"},"metadata":{}}]},{"cell_type":"code","source":"#To Get the filename with pathname and folder name for label in Testing folder\nfile_path=[] # File name\nlabel=[]  # folder name\nfor subfolder in os.listdir(testing_folder):\n    sub_folder_path=os.path.join(testing_folder,subfolder)\n    if os.path.isdir(sub_folder_path):\n        for file_name in os.listdir(sub_folder_path):\n            path=os.path.join(sub_folder_path,file_name)\n            if os.path.isfile(path):\n                file_path.append(path)\n                label.append(subfolder)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T11:56:22.534522Z","iopub.execute_input":"2024-08-03T11:56:22.535157Z","iopub.status.idle":"2024-08-03T11:56:47.251417Z","shell.execute_reply.started":"2024-08-03T11:56:22.535124Z","shell.execute_reply":"2024-08-03T11:56:47.250566Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# To create a Dataframe for the testing data\ndata={\n    'file_path':file_path,\n    'label':label\n}\ntest_df=pd.DataFrame(data)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-03T11:56:49.207287Z","iopub.execute_input":"2024-08-03T11:56:49.207695Z","iopub.status.idle":"2024-08-03T11:56:49.216619Z","shell.execute_reply.started":"2024-08-03T11:56:49.207662Z","shell.execute_reply":"2024-08-03T11:56:49.215695Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#Check the Testing data\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T11:56:52.127587Z","iopub.execute_input":"2024-08-03T11:56:52.127966Z","iopub.status.idle":"2024-08-03T11:56:52.137853Z","shell.execute_reply.started":"2024-08-03T11:56:52.127938Z","shell.execute_reply":"2024-08-03T11:56:52.136883Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                                           file_path                 label\n0  /kaggle/input/leaf-disease-detection-dataset/d...  Tomato___Late_blight\n1  /kaggle/input/leaf-disease-detection-dataset/d...  Tomato___Late_blight\n2  /kaggle/input/leaf-disease-detection-dataset/d...  Tomato___Late_blight\n3  /kaggle/input/leaf-disease-detection-dataset/d...  Tomato___Late_blight\n4  /kaggle/input/leaf-disease-detection-dataset/d...  Tomato___Late_blight","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_path</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/leaf-disease-detection-dataset/d...</td>\n      <td>Tomato___Late_blight</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/leaf-disease-detection-dataset/d...</td>\n      <td>Tomato___Late_blight</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/leaf-disease-detection-dataset/d...</td>\n      <td>Tomato___Late_blight</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/leaf-disease-detection-dataset/d...</td>\n      <td>Tomato___Late_blight</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/leaf-disease-detection-dataset/d...</td>\n      <td>Tomato___Late_blight</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Shape of the Testing Data\ntest_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-03T11:56:53.383482Z","iopub.execute_input":"2024-08-03T11:56:53.384429Z","iopub.status.idle":"2024-08-03T11:56:53.390946Z","shell.execute_reply.started":"2024-08-03T11:56:53.384388Z","shell.execute_reply":"2024-08-03T11:56:53.389853Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(17572, 2)"},"metadata":{}}]},{"cell_type":"code","source":"#To initialize the values\nwidth,height,depth=256,256,3\nbatch_size=32\nclass_mode=\"categorical\"\nscale=True\nrescale=None\nif scale:\n    rescale=1./255","metadata":{"execution":{"iopub.status.busy":"2024-08-03T13:32:51.011161Z","iopub.execute_input":"2024-08-03T13:32:51.011888Z","iopub.status.idle":"2024-08-03T13:32:51.017509Z","shell.execute_reply.started":"2024-08-03T13:32:51.011853Z","shell.execute_reply":"2024-08-03T13:32:51.016332Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#Training Data Preprocessing\ntrain_datagen=ImageDataGenerator(\n    rescale=rescale,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    validation_split=0.2\n                                 )","metadata":{"execution":{"iopub.status.busy":"2024-08-03T13:32:51.695311Z","iopub.execute_input":"2024-08-03T13:32:51.696180Z","iopub.status.idle":"2024-08-03T13:32:51.700339Z","shell.execute_reply.started":"2024-08-03T13:32:51.696147Z","shell.execute_reply":"2024-08-03T13:32:51.699488Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Test Data Preprocessing\ntest_datagen=ImageDataGenerator(\n    rescale=rescale,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T13:32:53.537684Z","iopub.execute_input":"2024-08-03T13:32:53.538348Z","iopub.status.idle":"2024-08-03T13:32:53.542519Z","shell.execute_reply.started":"2024-08-03T13:32:53.538316Z","shell.execute_reply":"2024-08-03T13:32:53.541630Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#Training Data\ntraining_data=train_datagen.flow_from_directory(\n    training_folder,\n    target_size=(width,height),\n    batch_size=batch_size,\n    class_mode=class_mode,\n    subset=\"training\"\n    )","metadata":{"execution":{"iopub.status.busy":"2024-08-03T13:32:55.036494Z","iopub.execute_input":"2024-08-03T13:32:55.036918Z","iopub.status.idle":"2024-08-03T13:33:24.481861Z","shell.execute_reply.started":"2024-08-03T13:32:55.036888Z","shell.execute_reply":"2024-08-03T13:33:24.481086Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Found 56251 images belonging to 38 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Validation Data\nvalidation_data=train_datagen.flow_from_directory(\n    training_folder,\n    target_size=(width,height),\n    batch_size=batch_size,\n    class_mode=class_mode,\n    subset=\"validation\"\n    )","metadata":{"execution":{"iopub.status.busy":"2024-08-03T13:33:29.315123Z","iopub.execute_input":"2024-08-03T13:33:29.315948Z","iopub.status.idle":"2024-08-03T13:33:39.869904Z","shell.execute_reply.started":"2024-08-03T13:33:29.315916Z","shell.execute_reply":"2024-08-03T13:33:39.869145Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Found 14044 images belonging to 38 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"#Testing Data\ntesting_data=test_datagen.flow_from_directory(\n    testing_folder,\n    target_size=(width,height),\n    batch_size=batch_size,\n    class_mode=class_mode\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T13:33:41.668243Z","iopub.execute_input":"2024-08-03T13:33:41.669023Z","iopub.status.idle":"2024-08-03T13:33:43.203911Z","shell.execute_reply.started":"2024-08-03T13:33:41.668988Z","shell.execute_reply":"2024-08-03T13:33:43.202956Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Found 17572 images belonging to 38 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"true_labels = testing_data.classes","metadata":{"execution":{"iopub.status.busy":"2024-08-03T13:33:45.817509Z","iopub.execute_input":"2024-08-03T13:33:45.818246Z","iopub.status.idle":"2024-08-03T13:33:45.822012Z","shell.execute_reply.started":"2024-08-03T13:33:45.818216Z","shell.execute_reply":"2024-08-03T13:33:45.821122Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"true_labels","metadata":{"execution":{"iopub.status.busy":"2024-08-03T13:33:50.124497Z","iopub.execute_input":"2024-08-03T13:33:50.125137Z","iopub.status.idle":"2024-08-03T13:33:50.132506Z","shell.execute_reply.started":"2024-08-03T13:33:50.125109Z","shell.execute_reply":"2024-08-03T13:33:50.131502Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"array([ 0,  0,  0, ..., 37, 37, 37], dtype=int32)"},"metadata":{}}]},{"cell_type":"code","source":"#CNN Layers\nmodel=Sequential()\nmodel.add(Conv2D(32, kernel_size=(3,3),input_shape=(width,height,depth), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, kernel_size=(3,3),activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, kernel_size=(3,3),activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(96, kernel_size=(3,3),activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, kernel_size=(3,3),activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(128,activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(number_of_classes,activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2024-08-03T15:01:32.569212Z","iopub.execute_input":"2024-08-03T15:01:32.569919Z","iopub.status.idle":"2024-08-03T15:01:32.832378Z","shell.execute_reply.started":"2024-08-03T15:01:32.569880Z","shell.execute_reply":"2024-08-03T15:01:32.831620Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-03T15:01:37.945362Z","iopub.execute_input":"2024-08-03T15:01:37.945716Z","iopub.status.idle":"2024-08-03T15:01:37.956191Z","shell.execute_reply.started":"2024-08-03T15:01:37.945688Z","shell.execute_reply":"2024-08-03T15:01:37.955254Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"history=model.fit(\n    training_data,\n    steps_per_epoch=int(len(training_data)/10),\n    epochs=2,\n    validation_data=validation_data,\n    validation_steps=int(len(validation_data)/10),\n    callbacks=[early_stopping]\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T15:01:46.864722Z","iopub.execute_input":"2024-08-03T15:01:46.865647Z","iopub.status.idle":"2024-08-03T15:05:17.766479Z","shell.execute_reply.started":"2024-08-03T15:01:46.865614Z","shell.execute_reply":"2024-08-03T15:05:17.765651Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"Epoch 1/2\n","output_type":"stream"},{"name":"stderr","text":"2024-08-03 15:01:56.087583: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 0: 5.22285, expected 4.50617\n2024-08-03 15:01:56.087650: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 19: 4.83523, expected 4.11855\n2024-08-03 15:01:56.087660: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 20: 6.14347, expected 5.42679\n2024-08-03 15:01:56.087668: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 21: 5.72417, expected 5.00749\n2024-08-03 15:01:56.087676: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 29: 6.00776, expected 5.29109\n2024-08-03 15:01:56.087683: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 30: 5.39609, expected 4.67941\n2024-08-03 15:01:56.087691: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 31: 5.14673, expected 4.43005\n2024-08-03 15:01:56.087699: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 61: 5.93186, expected 5.21518\n2024-08-03 15:01:56.087707: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 67: 6.09497, expected 5.3783\n2024-08-03 15:01:56.087715: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 72: 4.9921, expected 4.27543\n2024-08-03 15:01:56.115895: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:697] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[32,32,254,254]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,3,256,256]{3,2,1,0}, f32[32,3,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} for eng20{k2=2,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-08-03 15:01:56.115925: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:312] Device: Tesla P100-PCIE-16GB\n2024-08-03 15:01:56.115934: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:313] Platform: Compute Capability 6.0\n2024-08-03 15:01:56.115941: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:314] Driver: 12040 (550.90.7)\n2024-08-03 15:01:56.115948: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:315] Runtime: <undefined>\n2024-08-03 15:01:56.115963: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:320] cudnn version: 8.9.0\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step - accuracy: 0.1975 - loss: 3.2081","output_type":"stream"},{"name":"stderr","text":"2024-08-03 15:03:21.813193: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 0: 5.22285, expected 4.50617\n2024-08-03 15:03:21.813247: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 19: 4.83523, expected 4.11855\n2024-08-03 15:03:21.813256: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 20: 6.14347, expected 5.42679\n2024-08-03 15:03:21.813264: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 21: 5.72417, expected 5.00749\n2024-08-03 15:03:21.813272: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 29: 6.00776, expected 5.29109\n2024-08-03 15:03:21.813280: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 30: 5.39609, expected 4.67941\n2024-08-03 15:03:21.813287: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 31: 5.14673, expected 4.43005\n2024-08-03 15:03:21.813295: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 61: 5.93186, expected 5.21518\n2024-08-03 15:03:21.813303: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 67: 6.09497, expected 5.3783\n2024-08-03 15:03:21.813311: E external/local_xla/xla/service/gpu/buffer_comparator.cc:153] Difference at 72: 4.9921, expected 4.27543\n2024-08-03 15:03:21.841529: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:697] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[32,32,254,254]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,3,256,256]{3,2,1,0}, f32[32,3,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} for eng20{k2=2,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-08-03 15:03:21.841561: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:312] Device: Tesla P100-PCIE-16GB\n2024-08-03 15:03:21.841570: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:313] Platform: Compute Capability 6.0\n2024-08-03 15:03:21.841580: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:314] Driver: 12040 (550.90.7)\n2024-08-03 15:03:21.841587: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:315] Runtime: <undefined>\n2024-08-03 15:03:21.841603: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:320] cudnn version: 8.9.0\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 576ms/step - accuracy: 0.1980 - loss: 3.2050 - val_accuracy: 0.0414 - val_loss: 10.4955\nEpoch 2/2\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 551ms/step - accuracy: 0.4594 - loss: 1.8639 - val_accuracy: 0.1032 - val_loss: 10.3186\n","output_type":"stream"}]},{"cell_type":"code","source":"cnn_loss, cnn_accuracy=model.evaluate(testing_data)\nprint(\"Testing Accuracy:\",cnn_accuracy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"cnn.h5\")","metadata":{"execution":{"iopub.status.busy":"2024-08-03T15:05:34.251858Z","iopub.execute_input":"2024-08-03T15:05:34.252801Z","iopub.status.idle":"2024-08-03T15:05:34.328356Z","shell.execute_reply.started":"2024-08-03T15:05:34.252763Z","shell.execute_reply":"2024-08-03T15:05:34.327652Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"model=load_model(\"cnn.h5\")","metadata":{"execution":{"iopub.status.busy":"2024-08-03T15:05:50.935938Z","iopub.execute_input":"2024-08-03T15:05:50.936316Z","iopub.status.idle":"2024-08-03T15:05:51.202146Z","shell.execute_reply.started":"2024-08-03T15:05:50.936277Z","shell.execute_reply":"2024-08-03T15:05:51.201451Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"#y_pred_probs_cnn = model.predict(testing_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_pred_cnn = np.argmax(y_pred_probs_cnn, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#report_cnn = classification_report(true_labels, y_pred_cnn)\n#print(report_cnn)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#accuracy_cnn=accuracy_score(true_labels, y_pred_cnn)\n#accuracy_cnn","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train CNN architectures \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Xception\nbase_model = Xception(weights='imagenet', include_top=False, input_shape=(width, height, depth))\n","metadata":{"execution":{"iopub.status.busy":"2024-08-03T15:28:38.661624Z","iopub.execute_input":"2024-08-03T15:28:38.662276Z","iopub.status.idle":"2024-08-03T15:28:39.576450Z","shell.execute_reply.started":"2024-08-03T15:28:38.662225Z","shell.execute_reply":"2024-08-03T15:28:39.575668Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"x = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation='relu')(x)  # Adjust units and activation as needed\npredictions = Dense(number_of_classes, activation='softmax')(x)\n\nmodel = Model(inputs=base_model.input, outputs=predictions)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-03T15:28:40.933929Z","iopub.execute_input":"2024-08-03T15:28:40.934292Z","iopub.status.idle":"2024-08-03T15:28:40.966293Z","shell.execute_reply.started":"2024-08-03T15:28:40.934259Z","shell.execute_reply":"2024-08-03T15:28:40.965598Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2024-08-03T15:28:42.020157Z","iopub.execute_input":"2024-08-03T15:28:42.020534Z","iopub.status.idle":"2024-08-03T15:28:42.029494Z","shell.execute_reply.started":"2024-08-03T15:28:42.020504Z","shell.execute_reply":"2024-08-03T15:28:42.028751Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T15:28:43.439368Z","iopub.execute_input":"2024-08-03T15:28:43.439749Z","iopub.status.idle":"2024-08-03T15:28:43.444295Z","shell.execute_reply.started":"2024-08-03T15:28:43.439718Z","shell.execute_reply":"2024-08-03T15:28:43.443322Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"history = model.fit(training_data, steps_per_epoch=int(len(training_data)/10),epochs=20, batch_size=32,validation_data=validation_data, validation_steps=int(len(validation_data)/10), callbacks=[early_stopping])","metadata":{"execution":{"iopub.status.busy":"2024-08-03T15:28:44.557686Z","iopub.execute_input":"2024-08-03T15:28:44.558524Z","iopub.status.idle":"2024-08-03T15:55:13.523667Z","shell.execute_reply.started":"2024-08-03T15:28:44.558481Z","shell.execute_reply":"2024-08-03T15:55:13.522742Z"},"trusted":true},"execution_count":86,"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 470ms/step - accuracy: 0.5928 - loss: 1.5436\nEpoch 2/20\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 477ms/step - accuracy: 0.8731 - loss: 0.4325\nEpoch 3/20\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 475ms/step - accuracy: 0.8905 - loss: 0.3557\nEpoch 4/20\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 470ms/step - accuracy: 0.9256 - loss: 0.2667\nEpoch 5/20\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 472ms/step - accuracy: 0.9298 - loss: 0.2275\nEpoch 6/20\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 464ms/step - accuracy: 0.9349 - loss: 0.2210\nEpoch 7/20\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 461ms/step - accuracy: 0.9475 - loss: 0.1920\nEpoch 8/20\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 460ms/step - accuracy: 0.9463 - loss: 0.1921\nEpoch 9/20\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 460ms/step - accuracy: 0.9474 - loss: 0.1828\nEpoch 10/20\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 520ms/step - accuracy: 0.9566 - loss: 0.1443\nEpoch 11/20\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9651 - loss: 0.1371  \nEpoch 12/20\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 455ms/step - accuracy: 0.9541 - loss: 0.1490\nEpoch 13/20\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 453ms/step - accuracy: 0.9680 - loss: 0.1075\nEpoch 14/20\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 459ms/step - accuracy: 0.9583 - loss: 0.1344\nEpoch 15/20\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 455ms/step - accuracy: 0.9614 - loss: 0.1184\nEpoch 16/20\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 454ms/step - accuracy: 0.9641 - loss: 0.1109\nEpoch 17/20\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 454ms/step - accuracy: 0.9754 - loss: 0.0859\nEpoch 18/20\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 452ms/step - accuracy: 0.9557 - loss: 0.1494\nEpoch 19/20\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 456ms/step - accuracy: 0.9669 - loss: 0.1023\nEpoch 20/20\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 460ms/step - accuracy: 0.9607 - loss: 0.1223\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save(\"exception.h5\")","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:00:02.766623Z","iopub.execute_input":"2024-08-03T16:00:02.767009Z","iopub.status.idle":"2024-08-03T16:00:03.794050Z","shell.execute_reply.started":"2024-08-03T16:00:02.766978Z","shell.execute_reply":"2024-08-03T16:00:03.792968Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"exception_loss, exception_accuracy = model_exception.evaluate(testing_data)\nprint(f\"Testing Accuracy: {exception_accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-03T14:38:11.292083Z","iopub.status.idle":"2024-08-03T14:38:11.292421Z","shell.execute_reply.started":"2024-08-03T14:38:11.292251Z","shell.execute_reply":"2024-08-03T14:38:11.292265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import save_model","metadata":{"execution":{"iopub.status.busy":"2024-08-03T14:22:56.113243Z","iopub.execute_input":"2024-08-03T14:22:56.113633Z","iopub.status.idle":"2024-08-03T14:22:56.117923Z","shell.execute_reply.started":"2024-08-03T14:22:56.113597Z","shell.execute_reply":"2024-08-03T14:22:56.117013Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"save_model(model_exception,\"exception.h5\")","metadata":{"execution":{"iopub.status.busy":"2024-08-03T15:00:44.991685Z","iopub.execute_input":"2024-08-03T15:00:44.992301Z","iopub.status.idle":"2024-08-03T15:00:45.396910Z","shell.execute_reply.started":"2024-08-03T15:00:44.992265Z","shell.execute_reply":"2024-08-03T15:00:45.395999Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model","metadata":{"execution":{"iopub.status.busy":"2024-08-03T15:25:55.368638Z","iopub.execute_input":"2024-08-03T15:25:55.369011Z","iopub.status.idle":"2024-08-03T15:25:55.373848Z","shell.execute_reply.started":"2024-08-03T15:25:55.368982Z","shell.execute_reply":"2024-08-03T15:25:55.372699Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"model=load_model(\"exception.h5\")","metadata":{"execution":{"iopub.status.busy":"2024-08-03T15:26:03.011696Z","iopub.execute_input":"2024-08-03T15:26:03.013058Z","iopub.status.idle":"2024-08-03T15:26:03.977455Z","shell.execute_reply.started":"2024-08-03T15:26:03.013019Z","shell.execute_reply":"2024-08-03T15:26:03.976604Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# VGG16","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model_vgg16 = VGG16(\n    input_shape=(width, height, depth),\n    include_top=False,\n    weights='imagenet',\n    pooling=\"max\",\n    classifier_activation=\"softmax\"\n)\nbase_model_vgg16.trainable = False  # Freeze the base model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_vgg16 = Sequential([\n    base_model_vgg16,\n    Dense(128, activation='relu'),\n    Dropout(0.2),\n    Dense(number_of_classes, activation='softmax')  # Change the output units based on your number of classes\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_vgg16.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_vgg16=model_vgg16.fit(\n    training_data,\n    steps_per_epoch=int(len(training_data)/10),\n    epochs=20,\n    validation_data=validation_data,\n    validation_steps=int(len(validation_data)/10),\n    callbacks=[early_stopping]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg16_loss, vgg16_accuracy = model_vgg16.evaluate(testing_data)\nprint(f\"Testing Accuracy: {vgg16_accuracy}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#VGG19","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model_vgg19 = VGG19(\n    input_shape=(width, height, depth),\n    include_top=False,\n    weights='imagenet',\n    pooling=\"max\",\n    classifier_activation=\"softmax\"\n)\nbase_model_vgg19.trainable = False  # Freeze the base model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_vgg19 = Sequential([\n    base_model_vgg19,\n    Dense(128, activation='relu'),\n    Dropout(0.2),\n    Dense(number_of_classes, activation='softmax')  # Change the output units based on your number of classes\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_vgg19.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_vgg19=model_vgg19.fit(\n    training_data,\n    steps_per_epoch=int(len(training_data)/10),\n    epochs=20,\n    validation_data=validation_data,\n    validation_steps=int(len(validation_data)/10),\n    callbacks=[early_stopping]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg19_loss, vgg19_accuracy = model_vgg19.evaluate(testing_data)\nprint(f\"Testing Accuracy: {vgg19_accuracy}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Resnet50","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model_resnet50 = ResNet50(\n    input_shape=(width, height, depth),\n    include_top=False,\n    weights='imagenet',\n    pooling=\"max\",\n    classifier_activation=\"softmax\"\n)\nbase_model_resnet50.trainable = False  # Freeze the base model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_resnet50 = Sequential([\n    base_model_resnet50,\n    Dense(128, activation='relu'),\n    Dropout(0.2),\n    Dense(number_of_classes, activation='softmax')  # Change the output units based on your number of classes\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_resnet50.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_resnet50=model_resnet50.fit(\n    training_data,\n    steps_per_epoch=int(len(training_data)/10),\n    epochs=20,\n    validation_data=validation_data,\n    validation_steps=int(len(validation_data)/10),\n    callbacks=[early_stopping]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet50_loss,resnet50_accuracy = model_resnet50.evaluate(testing_data)\nprint(f\"Testing Accuracy: {resnet50_accuracy}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#InceptionV3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model_inceptionv3 = InceptionV3(\n    input_shape=(width, height, depth),\n    include_top=False,\n    weights='imagenet',\n    pooling=\"max\",\n    classifier_activation=\"softmax\"\n)\nbase_model_inceptionv3.trainable = False  # Freeze the base model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_inceptionv3 = Sequential([\n    base_model_inceptionv3,\n    Dense(128, activation='relu'),\n    Dropout(0.2),\n    Dense(number_of_classes, activation='softmax')  # Change the output units based on your number of classes\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_inceptionv3.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_inceptionv3=model_inceptionv3.fit(\n    training_data,\n    steps_per_epoch=int(len(training_data)/10),\n    epochs=20,\n    validation_data=validation_data,\n    validation_steps=int(len(validation_data)/10),\n    callbacks=[early_stopping]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inceptionv3_loss,inceptionv3_accuracy = model_inceptionv3.evaluate(testing_data)\nprint(f\"Testing Accuracy: {inceptionv3_accuracy}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_image(img_path):\n    # Preprocess the image\n    #img_path = '/kaggle/input/leaf-disease-detection-dataset/images_for_test/AppleCedarRust2.JPG'\n    img = image.load_img(img_path, target_size=(256, 256))  # Adjust target_size as per your model's input size\n    # Preprocess the image\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0)\n    img_array = img_array / 255.0  # Normalize the image if required by your model\n    return img_array","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_image(img_path):\n    # Predict the class\n    processed_image=preprocess_image(img_path)\n    predictions = model_exception.predict(processed_image)\n    # Interpret the output\n    predicted_class = np.argmax(predictions, axis=1)\n    #print(f'Predicted class: {predicted_class}')\n    return predicted_class","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names=sorted(os.listdir(\"/kaggle/input/leaf-disease-detection-dataset/dataset/train\"))\nprint(class_names)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T13:02:24.513532Z","iopub.execute_input":"2024-08-03T13:02:24.514010Z","iopub.status.idle":"2024-08-03T13:02:24.529800Z","shell.execute_reply.started":"2024-08-03T13:02:24.513975Z","shell.execute_reply":"2024-08-03T13:02:24.528865Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"['Apple___Apple_scab',\n 'Apple___Black_rot',\n 'Apple___Cedar_apple_rust',\n 'Apple___healthy',\n 'Blueberry___healthy',\n 'Cherry_(including_sour)___Powdery_mildew',\n 'Cherry_(including_sour)___healthy',\n 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot',\n 'Corn_(maize)___Common_rust_',\n 'Corn_(maize)___Northern_Leaf_Blight',\n 'Corn_(maize)___healthy',\n 'Grape___Black_rot',\n 'Grape___Esca_(Black_Measles)',\n 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)',\n 'Grape___healthy',\n 'Orange___Haunglongbing_(Citrus_greening)',\n 'Peach___Bacterial_spot',\n 'Peach___healthy',\n 'Pepper,_bell___Bacterial_spot',\n 'Pepper,_bell___healthy',\n 'Potato___Early_blight',\n 'Potato___Late_blight',\n 'Potato___healthy',\n 'Raspberry___healthy',\n 'Soybean___healthy',\n 'Squash___Powdery_mildew',\n 'Strawberry___Leaf_scorch',\n 'Strawberry___healthy',\n 'Tomato___Bacterial_spot',\n 'Tomato___Early_blight',\n 'Tomato___Late_blight',\n 'Tomato___Leaf_Mold',\n 'Tomato___Septoria_leaf_spot',\n 'Tomato___Spider_mites Two-spotted_spider_mite',\n 'Tomato___Target_Spot',\n 'Tomato___Tomato_Yellow_Leaf_Curl_Virus',\n 'Tomato___Tomato_mosaic_virus',\n 'Tomato___healthy']\n","output_type":"stream"}]},{"cell_type":"code","source":"true=[]\npred=[]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testing_image=\"/kaggle/input/leaf-disease-detection-dataset/images_for_test\"\nfor images in os.listdir(testing_image):\n    img_path=testing_image+'/'+images\n    predictions=predict_image(img_path)\n    print(images)\n    true.append(images)\n    result=class_names[predictions[0]]\n    print(result)\n    pred.append(result)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(true)):\n    print(true[i], pred[i])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras \nprint(f\"Keras version: {keras.__version__}\")\nprint(f\"TensorFlow version: {tf.__version__}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-03T13:29:46.862979Z","iopub.execute_input":"2024-08-03T13:29:46.863518Z","iopub.status.idle":"2024-08-03T13:29:46.898358Z","shell.execute_reply.started":"2024-08-03T13:29:46.863471Z","shell.execute_reply":"2024-08-03T13:29:46.897481Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Keras version: 3.4.1\nTensorFlow version: 2.17.0\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}