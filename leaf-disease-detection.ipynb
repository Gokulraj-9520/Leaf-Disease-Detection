{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3814063,"sourceType":"datasetVersion","datasetId":2272471}],"dockerImageVersionId":30748,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tensorflow --upgrade ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Required Libraries\nimport numpy as np\nimport pandas as pd\nimport os\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom tensorflow import *\nfrom tensorflow import keras\nfrom keras.models import Sequential, Model\nfrom tensorflow.keras.applications import *\nfrom keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Dropout,BatchNormalization,GlobalAveragePooling2D\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Copy and paste the training and testing folder in training and testing variable\ntraining_folder=r\"/kaggle/input/leaf-disease-detection-dataset/dataset/train\"\ntesting_folder=r\"/kaggle/input/leaf-disease-detection-dataset/dataset/test\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find the Number of classess\nnumber_of_classes=len(os.listdir(training_folder))\nprint(f\"Number of classes: {number_of_classes}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Find the Number of images in Training folder\ntotal_number_of_images_in_training=0\nfolder_path=os.listdir(training_folder)\nfor i,folder in enumerate(folder_path):\n    number_of_images=len(os.listdir(training_folder+'/'+folder))\n    total_number_of_images_in_training+=number_of_images\n    print(f\"{i} , In {folder} folder contains {number_of_images} images.\")\n\nprint(f\"Total Number of Images in Training Folder: {total_number_of_images_in_training}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Find the Number of images in Testing folder\ntotal_number_of_images_in_testing=0\nfolder_path=os.listdir(testing_folder)\nfor i,folder in enumerate(folder_path):\n    number_of_images=len(os.listdir(testing_folder+'/'+folder))\n    total_number_of_images_in_testing+=number_of_images\n    print(f\"{i}, In {folder} folder contains {number_of_images} images.\")\n\nprint(f\"Total Number of Images in Testing Folder: {total_number_of_images_in_testing}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#To Get the filename with pathname and folder name for label for Training Folder\nfile_path=[] # File name\nlabel=[]  # folder name\nfor subfolder in os.listdir(training_folder):\n    sub_folder_path=os.path.join(training_folder,subfolder)\n    if os.path.isdir(sub_folder_path):\n        for file_name in os.listdir(sub_folder_path):\n            path=os.path.join(sub_folder_path,file_name)\n            if os.path.isfile(path):\n                file_path.append(path)\n                label.append(subfolder)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To create a Dataframe for the training data\ndata={\n    'file_path':file_path,\n    'label':label\n}\ntrain_df=pd.DataFrame(data)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check the Training data\ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Shape of the Training Data\ntrain_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#To Get the filename with pathname and folder name for label in Testing folder\nfile_path=[] # File name\nlabel=[]  # folder name\nfor subfolder in os.listdir(testing_folder):\n    sub_folder_path=os.path.join(testing_folder,subfolder)\n    if os.path.isdir(sub_folder_path):\n        for file_name in os.listdir(sub_folder_path):\n            path=os.path.join(sub_folder_path,file_name)\n            if os.path.isfile(path):\n                file_path.append(path)\n                label.append(subfolder)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To create a Dataframe for the testing data\ndata={\n    'file_path':file_path,\n    'label':label\n}\ntest_df=pd.DataFrame(data)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check the Testing data\ntest_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Shape of the Testing Data\ntest_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#To initialize the values\nwidth,height,depth=256,256,3\nbatch_size=32\nclass_mode=\"categorical\"\nscale=True\nrescale=None\nif scale:\n    rescale=1./255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Training Data Preprocessing\ntrain_datagen=ImageDataGenerator(\n    rescale=rescale,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    validation_split=0.2\n                                 )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test Data Preprocessing\ntest_datagen=ImageDataGenerator(\n    rescale=rescale,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Training Data\ntraining_data=train_datagen.flow_from_directory(\n    training_folder,\n    target_size=(width,height),\n    batch_size=batch_size,\n    class_mode=class_mode,\n    subset=\"training\"\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Validation Data\nvalidation_data=train_datagen.flow_from_directory(\n    training_folder,\n    target_size=(width,height),\n    batch_size=batch_size,\n    class_mode=class_mode,\n    subset=\"validation\"\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Testing Data\ntesting_data=test_datagen.flow_from_directory(\n    testing_folder,\n    target_size=(width,height),\n    batch_size=batch_size,\n    class_mode=class_mode\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"true_labels = testing_data.classes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"true_labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#CNN Layers\nmodel=Sequential()\nmodel.add(Conv2D(32, kernel_size=(3,3),input_shape=(width,height,depth), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, kernel_size=(3,3),activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, kernel_size=(3,3),activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(96, kernel_size=(3,3),activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, kernel_size=(3,3),activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(128,activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(number_of_classes,activation='softmax'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history=model.fit(\n    training_data,\n    steps_per_epoch=int(len(training_data)/10),\n    epochs=2,\n    validation_data=validation_data,\n    validation_steps=int(len(validation_data)/10),\n    callbacks=[early_stopping]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_loss, cnn_accuracy=model.evaluate(testing_data)\nprint(\"Testing Accuracy:\",cnn_accuracy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"cnn.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=load_model(\"cnn.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_pred_probs_cnn = model.predict(testing_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_pred_cnn = np.argmax(y_pred_probs_cnn, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#report_cnn = classification_report(true_labels, y_pred_cnn)\n#print(report_cnn)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#accuracy_cnn=accuracy_score(true_labels, y_pred_cnn)\n#accuracy_cnn","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train CNN architectures \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Xception\nbase_model_exception = Xception(weights='imagenet', include_top=False, input_shape=(width, height, depth))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = base_model_exception.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation='relu')(x)  # Adjust units and activation as needed\npredictions = Dense(number_of_classes, activation='softmax')(x)\n\nmodel_exception = Model(inputs=base_model.input, outputs=predictions)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_exception.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model_exception.fit(training_data, steps_per_epoch=int(len(training_data)/10),epochs=20, batch_size=32,validation_data=validation_data, validation_steps=int(len(validation_data)/10), callbacks=[early_stopping])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"exception_loss, exception_accuracy = model_exception.evaluate(testing_data)\nprint(f\"Testing Accuracy: {exception_accuracy}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import save_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_model(model_exception,\"exception.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=load_model(\"exception.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# VGG16","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model_vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(width, height, depth))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = base_model_vgg16.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation='relu')(x)  # Adjust units and activation as needed\npredictions = Dense(number_of_classes, activation='softmax')(x)\n\nmodel_vgg16 = Model(inputs=base_model.input, outputs=predictions)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_vgg16.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_vgg16=model_vgg16.fit(\n    training_data,\n    steps_per_epoch=int(len(training_data)/10),\n    epochs=20,\n    validation_data=validation_data,\n    validation_steps=int(len(validation_data)/10),\n    callbacks=[early_stopping]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg16_loss, vgg16_accuracy = model_vgg16.evaluate(testing_data)\nprint(f\"Testing Accuracy: {vgg16_accuracy}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#VGG19","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model_vgg19 = VGG19(\n    input_shape=(width, height, depth),\n    include_top=False,\n    weights='imagenet')\n # Freeze the base model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = base_model_vgg19.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation='relu')(x)  # Adjust units and activation as needed\npredictions = Dense(number_of_classes, activation='softmax')(x)\n\nmodel_vgg19 = Model(inputs=base_model.input, outputs=predictions)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_vgg19.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_vgg19=model_vgg19.fit(\n    training_data,\n    steps_per_epoch=int(len(training_data)/10),\n    epochs=20,\n    validation_data=validation_data,\n    validation_steps=int(len(validation_data)/10),\n    callbacks=[early_stopping]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg19_loss, vgg19_accuracy = model_vgg19.evaluate(testing_data)\nprint(f\"Testing Accuracy: {vgg19_accuracy}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Resnet50","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model_resnet50 = ResNet50(\n    input_shape=(width, height, depth),\n    include_top=False,\n    weights='imagenet',\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = base_model_resnet50.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation='relu')(x)  # Adjust units and activation as needed\npredictions = Dense(number_of_classes, activation='softmax')(x)\n\nmodel_resnet50 = Model(inputs=base_model.input, outputs=predictions)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_resnet50.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_resnet50=model_resnet50.fit(\n    training_data,\n    steps_per_epoch=int(len(training_data)/10),\n    epochs=20,\n    validation_data=validation_data,\n    validation_steps=int(len(validation_data)/10),\n    callbacks=[early_stopping]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet50_loss,resnet50_accuracy = model_resnet50.evaluate(testing_data)\nprint(f\"Testing Accuracy: {resnet50_accuracy}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#InceptionV3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model_inceptionv3 = InceptionV3(\n    input_shape=(width, height, depth),\n    include_top=False,\n    weights='imagenet')  # Freeze the base model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = base_model_inceptionv3.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation='relu')(x)  # Adjust units and activation as needed\npredictions = Dense(number_of_classes, activation='softmax')(x)\n\nmodel_inceptionv3 = Model(inputs=base_model.input, outputs=predictions)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_inceptionv3.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_inceptionv3=model_inceptionv3.fit(\n    training_data,\n    steps_per_epoch=int(len(training_data)/10),\n    epochs=20,\n    validation_data=validation_data,\n    validation_steps=int(len(validation_data)/10),\n    callbacks=[early_stopping]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inceptionv3_loss,inceptionv3_accuracy = model_inceptionv3.evaluate(testing_data)\nprint(f\"Testing Accuracy: {inceptionv3_accuracy}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_image(img_path):\n    # Preprocess the image\n    #img_path = '/kaggle/input/leaf-disease-detection-dataset/images_for_test/AppleCedarRust2.JPG'\n    img = image.load_img(img_path, target_size=(256, 256))  # Adjust target_size as per your model's input size\n    # Preprocess the image\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0)\n    img_array = img_array / 255.0  # Normalize the image if required by your model\n    return img_array","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_image(img_path):\n    # Predict the class\n    processed_image=preprocess_image(img_path)\n    predictions = model_exception.predict(processed_image)\n    # Interpret the output\n    predicted_class = np.argmax(predictions, axis=1)\n    #print(f'Predicted class: {predicted_class}')\n    return predicted_class","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names=sorted(os.listdir(\"/kaggle/input/leaf-disease-detection-dataset/dataset/train\"))\nprint(class_names)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"true=[]\npred=[]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testing_image=\"/kaggle/input/leaf-disease-detection-dataset/images_for_test\"\nfor images in os.listdir(testing_image):\n    img_path=testing_image+'/'+images\n    predictions=predict_image(img_path)\n    print(images)\n    true.append(images)\n    result=class_names[predictions[0]]\n    print(result)\n    pred.append(result)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(true)):\n    print(true[i], pred[i])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras \nprint(f\"Keras version: {keras.__version__}\")\nprint(f\"TensorFlow version: {tf.__version__}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}